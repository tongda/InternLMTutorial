# 课程及InternLM2 技术报告笔记

## 书生·浦语大模型全链路开源体系

总结如下：

1. **通用人工智能的进展方向**：从专注于单一任务的模型转向通用大模型，能够应对多种任务和模态。
2. **书生·浦语模型升级**：在7月进行了升级，支持8K上下文和工具体系；在8月发布了对话模型和智能体框架；并在9月推出了中等尺寸模型与优化工具链；2024 年 1 月 17 日，InternLM2开源。
3. **InternLM2的开源**：提升了模型性能，以应对复杂场景，并提供了不同尺寸（7B 和 20B，相比国内其他厂商只开源 7B，InternLM2 非常有诚意）的模型以满足不同需求。
4. **模型的核心能力**：包括长上下文理解、对话与创作、数学能力等，例如进行行程规划和情感对话等任务。
5. **InternLM2的优化**：通过数据清洗、高质量语料和新数据补全来提升模型性能（Loss 分布左移）。
6. **下游任务的性能提升**：模型使用更少数据也能达到上一代效果，整体性能得到了提升。
7. **开源工具生态**：包括数据到预训练、微调、部署和评测等全流程工具，如书生万卷数据集，InternLM-Train，XTuner，LMDeploy，OpenCompass，LAgent&AgentLego等。
8. **数据集**：提供了丰富多样的数据，支持数据清洗、安全处理和公开使用。
9. **性能评估与差距**：大模型整体能力仍有提升空间，尤其在理科能力上，在中文场景下国内模型表现出色。
10. **部署解决方案**：LMDeploy支持模型轻量化、量化和推理服务，并与评测工具无缝对接。

## InterLM2 技术文档

### 基础设施

1. **训练框架**：使用 InterEvo 作为分布式训练框架，这个框架在 GPU 节点增加和序列长度增加的情况下，依然保持较高的 MFU (Model FLOPs Utilization)。
2. **模型架构**：遵循 LLaMa 架构，采用了一些训练技巧，在 InternLM2 中独特的 QKV 矩阵排列方式，能够提升张量并行的效率。

### 预训练

1. **数据**：数据质量对于训练模型非常关键，该技术文档花了很大篇幅讲数据。对于文本数据，代码数据，长上下文数据都给出了非常详细的处理过程。
2. **预训练设置**：包括Token策略，超参选择。
3. **预训练阶段**：将预训练过程分为 3 个阶段。第一阶段（占 90% 的 step）用不超过 4k 上下文的语料进行训练；第二个阶段（9% 的 step），预料中包含 50% 的 32k 上下文语料；第三阶段，加入能力增强数据。每个阶段都包含中文英文和代码数据。

### 对齐

1. **SFT（Supervised Fine-Tuning）**：筛选出 1000 万指令数据，覆盖各种场景，7B 和 20B 模型分别用这个数据跑一个 Epoch。
2. **COOL RLHF**：使用条件（Coditional）奖励来解决选择冲突；多轮在线（Online）RLHF 减轻奖励破坏。PPO 训练，引入四个模型，执行模型，评价模型，引用模型，奖励模型，冻结后两个，训练前两个。
3. **长上下文微调**：除了从电子书中提取的长上下文，还包括了代码，提取了 DS-1000 数据集以及 github 上标星超过 10000 的代码库，经过一些预处理，加入 SFT 数据集。
4. **工具增强 LLM**：对于工具调用，采用改进的 ChatML 格式，引入“环境”角色，生成通用工具调用。对于代码解释器，将 Python 代码调用当成一种特殊的工具。

### 评估与分析

主要分为两部分，1）下游任务和 2）对齐。

*评：目前的大模型性能，架构上各家并没有谁有明显的技术优势，毕竟开源生态种，大家都是互相借鉴，真正决定模型性能的，还是训练数据的质量。* 

1. 下游任务：

* **复杂考试**：InternLM2-7B-Base 模型相比 ChatGLM3-6B-Base，弱了一些，不过 InternLM2-7B 还是有明显提升，5 项测试里，2 项最高分。而 20B 模型，只有一项取得了最高分，Qwen-14B 有 3 项最高，Mixtral-8x7B 有一项得到最高分。总体来看 7B 模型可以和 ChatGLM3 有一拼，20B 和 Qwen-14B 有一拼。
* **语言和知识**：和前面的结果差不多，InterLM2能够赢一到两个项目。
* **推理和数学**：这一项上 InternLM2 赢了大部分评测，甚至 7B 模型就已经表现的很不错了。估计是预训练的最后一个阶段，使用领域精调数据训练对模型的提升有作用。
* **写代码**：主要看 Python 代码的编写能力，这里有点奇怪，在 HumanEval 和 MBPP 数据集上，20B 模型比 7B 模型还要更差。
* **对比领域特定训练前后模型性能**：预训练阶段最后的 1% 步，使用了领域特定训练数据，虽然只有 1% 的迭代步数，但是在模型性能提升上非常明显。
* **长上下文建模**：在各种数据集上的指标都表现很不错，尤其是“大海捞针”测试，在 200K 上下文🔟模型还能保持不错的效果；
* **工具使用**：简单来说，7B 模型没对手，20B 模型很突出。

2. 对齐：分英语，中文，指令遵循等角度分别评测，基本都相比一代模型有明显提升。*这里没有提横向对比，不知道为什么。* 另外做了消融实验，验证了在 RLHF 阶段，加入条件奖励机制是有效的。

3. 数据污染讨论：这里提出了两个指标，Delta1 和 Delta2，分别用来表示测试数据泄露和模型过拟合。从数据上看，经过领域特定增强之后的模型，测试泄露的可能性挺高，而且也有些过拟合。*Qwen-14B 和 Baichuan2-13B 的过拟合指标都很高，可能国内大厂为了刷榜都训的挺狠的。相比之下，ChatGLM3-6B-Base 其实还挺正常。*

